{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import hashlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_proba(clf,X_train,y,X_test,nfolds=5,save_preds=\"\",save_test_only=\"\",seed=300373,\n",
    "               save_params=\"\",clf_name=\"XX\",generalizers_params=[],minimal_loss=0,return_score=False,minmizer='log_loss'):\n",
    "    print(\"\\nBlending with classifier:\\n\\t%s\"%(clf))\n",
    "    folds = list(cross_validation.StratifiedKFlod(y,nfolds,shuffle=True,random_state=seed))\n",
    "    print(X_train.shape)\n",
    "    dataset_blend_train = np.zeros((X_train.shape[0],np.unique(y).shape[0]))\n",
    "    loss = 0\n",
    "    for i ,(train_index,test_index) in enumerate(folds) :\n",
    "        print(\"Train Fold %s/%s\"%(i+1,nfolds))\n",
    "        fold_X_train = X_train[train_index]\n",
    "        fold_y_train = y[train_index]\n",
    "        fold_X_test = y[test_index]\n",
    "        fold_y_test = y[test_index]\n",
    "        clf.fit(fold_X_train,fold_y_train)\n",
    "        fold_preds = clf.predict_proba(fold_X_test)\n",
    "        print(\"Logistic loss: %s\"%log_loss(fold_y_test,fold_preds))\n",
    "        #pred to train\n",
    "        dataset_blend_train[test_index] = fold_preds\n",
    "        if minimizer == \"log_loss\":\n",
    "            loss += log_loss(fold_y_test,fold_preds)\n",
    "        if minimizer == \"accuracy\":\n",
    "            fold_preds_a = np.argmax(fold_preds,axis=1)\n",
    "            #return the class\n",
    "            loss += accuracy_score(fold_y_test,fold_preds_a)\n",
    "        if minimal_loss > 0 and loss > minimal_loss and i ==0:\n",
    "            return False,False\n",
    "        fold_preds = np.argmax(fold_preds,axis=1)\n",
    "        print(\"Accuracy:    %s\"%accuracy_score(fold_y_test,fold_preds))\n",
    "    avg_loss = loss/float(i+1)\n",
    "    print(\"\\nAverage:\\t%s\\n\"%avg_loss)\n",
    "    print(\"Test Fold 1/1\")\n",
    "    clf.fit(X_train,y)\n",
    "    dataset_blend_test = clf.predict_proba(X_test)\n",
    "    \n",
    "    if clf_name == \"XX\":\n",
    "        clf_name = str(clf)[1:3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(attempt,actual,epsilon=1.0e-15):\n",
    "    attempt = np.clip(attempt,epsilon,1.0-epsilon)\n",
    "    return -np.mean(actual*np.log(attempt)+(1.0-actual)*np.log(1.0-attempt))\n",
    "def blend(clfs,X,y,X_submission):\n",
    "    np.random.seed(0)\n",
    "    n_folds = 10\n",
    "    verbose = True\n",
    "    shuffle = False\n",
    "    #xi pai\n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(y.size)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "    skf = list(StratifiedKFold(y,n_folds))\n",
    "    print(\"Creating train and test sets for blending\")\n",
    "    dataset_blend_train = np.zeros((X.shape[0],len(clfs)))\n",
    "    dataset_blend_test = np.zeros((X_submission.shape[0],len(clfs)))\n",
    "    for j,clf in enumerate(clfs):\n",
    "        dataset_blend_test_j = np.zeros((X_submission.shape[0],len(skf)))\n",
    "        for i,(train,test) in enumerate(skf):\n",
    "            X_train = X[train]\n",
    "            y_train = y[train]\n",
    "            X_test = X[test]\n",
    "            y_test = y[test]\n",
    "            clf.fit(X_train,y_train)\n",
    "            y_submission = clf.predict_proba(X_test)[:,1]\n",
    "            dataset_blend_train[test,j] = y_submission\n",
    "            dataset_blend_test_j = clf.predict_proba(X_submission)[:,1]\n",
    "        dataset_blend_test[:,j] = dataset_blend_test_j.mean(1)\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(dataset_blend_train,y)\n",
    "    y_submission = clf.predict_proba(dataset_blend_test)[:,1]\n",
    "    #Linear stretch of predictions to [0,1]\n",
    "    y_submission = (y_submission - y_submission.min()) / (y_submission.max() - y_submission.min())\n",
    "    #SAVING \n",
    "    return y_submission\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
